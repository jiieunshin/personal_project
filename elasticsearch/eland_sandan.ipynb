{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "# import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\2616041819.py:4: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000001', 'cluster_name': 'eecca21c115f445e8c931ba15ea38596', 'cluster_uuid': 'WBZCstrTQp6hIifjC9xyRw', 'version': {'number': '8.11.1', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '6f9ff581fbcde658e6f69d6ce03050f060d1fd0c', 'build_date': '2023-11-11T10:05:59.421038163Z', 'build_snapshot': False, 'lucene_version': '9.8.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "ELASTIC_CLOUD_ID = \"jieun:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyRlZWNjYTIxYzExNWY0NDVlOGM5MzFiYTE1ZWEzODU5NiQ1Yzc1ODM1MDhmODk0OGU2YmRkOGQzYWIxOWViYWY4Mw==\"\n",
    "ELASTIC_CLOUD_PASSWORD= 'jieun123'\n",
    "\n",
    "es = Elasticsearch(\n",
    "  cloud_id=ELASTIC_CLOUD_ID,\n",
    "  http_auth=(\"jieun\", ELASTIC_CLOUD_PASSWORD)\n",
    ")\n",
    "\n",
    "print(es.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스의 매핑 정보 가져오기\n",
    "mapping_info = es.indices.get_mapping(index = '논문')\n",
    "\n",
    "# 매핑 정보 출력\n",
    "print(mapping_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 '논문' 삭제 완료\n"
     ]
    }
   ],
   "source": [
    "# 삭제할 인덱스 이름 지정\n",
    "index_name = \"논문\"  # 삭제하려는 인덱스 이름을 설정하세요\n",
    "\n",
    "# 인덱스 삭제 명령 실행\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"인덱스 '{index_name}' 삭제 완료\")\n",
    "else:\n",
    "    print(f\"인덱스 '{index_name}'는 이미 존재하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_embedding</th>\n",
       "      <th>교수명</th>\n",
       "      <th>기준년도</th>\n",
       "      <th>논문명</th>\n",
       "      <th>대학</th>\n",
       "      <th>연번</th>\n",
       "      <th>초록_영문</th>\n",
       "      <th>초록_요약</th>\n",
       "      <th>학과명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<p>0 rows × 9 columns</p>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_embedding, 교수명, 기준년도, 논문명, 대학, 연번, 초록_영문, 초록_요약, 학과명]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 9 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ed.DataFrame(es, es_index_pattern = \"논문\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding모델 불러와서 임포트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\eland\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from eland.ml import MLModel\n",
    "import elasticsearch\n",
    "from pathlib import Path\n",
    "from eland.common import es_version\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 11, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_cluster_version = es_version(es)\n",
    "es_cluster_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 236kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 47.5kB/s]\n",
      "README.md: 100%|██████████| 4.44k/4.44k [00:00<00:00, 723kB/s]\n",
      "config.json: 100%|██████████| 620/620 [00:00<00:00, 68.2kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 123/123 [00:00<00:00, 14.4kB/s]\n",
      "(…)imilarity_evaluation_sts-dev_results.csv: 100%|██████████| 930/930 [00:00<00:00, 127kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 443M/443M [00:45<00:00, 9.79MB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 10.4kB/s]\n",
      "(…)milarity_evaluation_sts-test_results.csv: 100%|██████████| 301/301 [00:00<00:00, 59.1kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 15.1kB/s]\n",
      "tokenizer.json: 100%|██████████| 495k/495k [00:00<00:00, 800kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 538/538 [00:00<00:00, 84.5kB/s]\n",
      "vocab.txt: 100%|██████████| 248k/248k [00:00<00:00, 421kB/s]\n",
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 63.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "# TransformerModel 로드\n",
    "tm = TransformerModel(model_id=\"jhgan/ko-sbert-sts\", task_type=\"text_embedding\", es_version=es_cluster_version)\n",
    "\n",
    "# Export the model in a TorchScrpt representation which Elasticsearch uses\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "print('model_path : ',model_path)\n",
    "print('config : ', config)\n",
    "print('vocab_path : ', vocab_path)\n",
    "\n",
    "# Import model into Elasticsearch\n",
    "ptm = PyTorchModel(es, tm.elasticsearch_model_id())\n",
    "print(ptm)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본격적인 vector search\n",
    "\n",
    "함수로 만들어놓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스와 엔드포인트 설정\n",
    "index_name = \"_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/deployment\"\n",
    "endpoint = \"_infer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 매핑 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'연번': {'type': 'long'},\n",
       "  '대학': {'type': 'text', 'analyzer': 'my_analyzer'},\n",
       "  '학과명': {'type': 'text', 'analyzer': 'my_analyzer'},\n",
       "  '교수명': {'type': 'text', 'analyzer': 'my_analyzer'},\n",
       "  '논문명': {'type': 'text', 'analyzer': 'my_analyzer'},\n",
       "  '기준년도': {'type': 'long'},\n",
       "  '초록_영문': {'type': 'text', 'analyzer': 'my_analyzer'},\n",
       "  '초록_국문': {'type': 'text', 'analyzer': 'my_analyzer'},\n",
       "  '초록_요약': {'type': 'text', 'analyzer': 'my_analyzer'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "## ES에 데이터 올리는 코드 ##\n",
    "###########################\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "# data_path = \"data/\"\n",
    "# csv_files = os.listdir(data_path)\n",
    "# dataframes = [pd.read_csv(data_path + file) for file in csv_files]\n",
    "# print(csv_files)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/논문.csv')\n",
    "df = df.fillna(0)\n",
    "index_name = \"논문\"\n",
    "\n",
    "field_name = df.columns.to_list()\n",
    "f_type = df.dtypes\n",
    "\n",
    "# Define a custom analyzer\n",
    "custom_analyzer = {\n",
    "    \"tokenizer\": \"my_tokenizer\",\n",
    "    \"filter\": [\"lowercase\", \"trim\", \"stop\", \"nori_filter\"]\n",
    "    # \"char_filter\": [\"html_strip\"]\n",
    "}\n",
    "\n",
    "# Define a custom filter for the analyzer\n",
    "# custom_filter = {\n",
    "#     \"type\": \"pattern_replace\",\n",
    "#     \"pattern\": \"[^a-zA-Z0-9가-힣\\\\s]\",\n",
    "#     \"replacement\": \" \"\n",
    "# }\n",
    "\n",
    "# Define a custom tokenizer\n",
    "custom_tokenizer = {\n",
    "    \"type\": \"nori_tokenizer\",\n",
    "    \"decompound_mode\": \"mixed\",\n",
    "    \"discard_punctuation\": False\n",
    "}\n",
    "\n",
    "# nori 토큰 필터 설정\n",
    "nori_filter = {\n",
    "    \"type\": \"nori_part_of_speech\",\n",
    "    \"stoptags\": [\"E\", \"IC\", \"J\", \"MAG\", \"MAJ\", \"MM\", \"SP\", \"SSC\", \"SSO\", \"SC\", \"SE\", \"XPN\", \"XSA\", \"XSN\", \"XSV\", \"UNA\", \"NA\", \"VSV\"]\n",
    "}\n",
    "\n",
    "# Create an index with custom analyzer and tokenizer settings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"my_analyzer\": custom_analyzer\n",
    "            },\n",
    "            \"filter\": {\n",
    "                # \"my_filter\": custom_filter,\n",
    "                \"nori_filter\": nori_filter\n",
    "            },\n",
    "            \"tokenizer\": {\n",
    "                \"my_tokenizer\": custom_tokenizer\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {}  # We'll add the properties dynamically\n",
    "    }\n",
    "}\n",
    "\n",
    "# Iterate through the dataframes and dynamically add properties to the mappings\n",
    "# for df in dataframes:\n",
    "fields = df.columns.tolist()\n",
    "\n",
    "for field in fields:\n",
    "    field_type = \"text\" if pd.api.types.is_string_dtype(df[field]) or pd.api.types.is_object_dtype(df[field]) else \"long\"\n",
    "    if field_type == \"text\":\n",
    "        index_settings[\"mappings\"][\"properties\"][field] = {\"type\": field_type, \"analyzer\": \"my_analyzer\"}\n",
    "    else:\n",
    "        index_settings[\"mappings\"][\"properties\"][field] = {\"type\": field_type}\n",
    "\n",
    "# # 임베딩 저장할 필드 추가\n",
    "# embed_mapp =  {\n",
    "#     \"type\": \"dense_vector\",\n",
    "#     \"dims\": 256,\n",
    "#     \"index\": \"true\",\n",
    "#     \"similarity\": \"cosine\"\n",
    "# }\n",
    "\n",
    "# index_settings[\"mappings\"][\"properties\"][\"text_embedding\"] = embed_mapp\n",
    "# embed_mapp2 = {\n",
    "#         \"excludes\": [\n",
    "#             \"text_embedding\"\n",
    "#         ]\n",
    "#     }\n",
    "# index_settings[\"mappings\"][\"_source\"] = embed_mapp2\n",
    "index_settings[\"mappings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, [])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the index with the defined settings\n",
    "es.indices.create(index = index_name, body = index_settings)\n",
    "\n",
    "# Bulk insert data into Elasticsearch\n",
    "actions = []\n",
    "for _, row in df.iterrows():\n",
    "    data = row.to_dict()\n",
    "    actions.extend([{\"_index\": index_name, \"_source\": data}])\n",
    "\n",
    "elasticsearch.helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# POST /_ml/trained_models/jhgan__ko-sbert-sts/_infer\n",
    "# {\n",
    "#   \"docs\": {\n",
    "#     \"text_field\": \"how is the weather in jamaica\"\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# // 1 post\n",
    "# PUT _ingest/pipeline/text-embeddings\n",
    "# {\n",
    "#   \"description\": \"Text embedding pipeline\",\n",
    "#   \"processors\": [\n",
    "#     {\n",
    "#       \"inference\": {\n",
    "#         \"model_id\": \"jhgan__ko-sbert-sts\",\n",
    "#         \"target_field\": \"text_embedding.predicted_value\",\n",
    "#         \"field_map\": {\n",
    "#           \"초록_요약\": \"text_field\"\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#   ],\n",
    "#   \"on_failure\": [\n",
    "#     {\n",
    "#       \"set\": {\n",
    "#         \"description\": \"Index document to 'failed-<index>'\",\n",
    "#         \"field\": \"_index\",\n",
    "#         \"value\": \"failed-{{{_index}}}\"\n",
    "#       }\n",
    "#     },\n",
    "#     {\n",
    "#       \"set\": {\n",
    "#         \"description\": \"Set error message\",\n",
    "#         \"field\": \"ingest.failure\",\n",
    "#         \"value\": \"{{_ingest.on_failure_message}}\"\n",
    "#       }\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "\n",
    "# // 3.  reindex\n",
    "# POST _reindex?wait_for_completion=false\n",
    "# {\n",
    "#   \"source\": {\n",
    "#     \"index\": \"논문\"\n",
    "#   },\n",
    "#   \"dest\": {\n",
    "#     \"index\": \"embeddings\",\n",
    "#     \"pipeline\": \"text-embeddings\"\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# GET _tasks/e0Np3C0QTb-4im2Tq7Gifw:7055257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1:\n",
      "Score: 0.73070997\n",
      "연번: 733\n",
      "학과명: 통계학과\n",
      "교수명: 박창이\n",
      "논문명: Negative binomial graphical model with excess zero\n",
      "초록_요약: 과분산 계수 데이터를 위한 새로운 그래픽 모델인 영과잉 지역 음이항 그래픽 모델을 제시합니다. 음이항 분포의 두 가지 매개변수화를 이용하여 목적 함수를 최적화하는 기대값-최소화 알고리즘을 설계합니다.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Row 2:\n",
      "Score: 0.70561326\n",
      "연번: 733\n",
      "학과명: 통계학과\n",
      "교수명: 박창이\n",
      "논문명: Multiclass Laplacian support vector machine with functional analysis of variance decomposition\n",
      "초록_요약: 이 논문은 다중 클래스 분류 문제에서 레이블이 지정되지 않은 샘플을 활용하여 더 나은 분류 함수를 학습하는 라플라시안 서포트 벡터 머신(LapSVM)을 제안합니다. 또한 LapSVM의 관련 없는 변수 문제를 해결하기 위해 분산 분해 기능 분석을 사용하는 다중 클래스 LapSVM을 소개하며, 이 방법이 효율적이고 분류 성능이 향상됨을 실험과 실제 데이터셋을 통해 입증합니다.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Row 3:\n",
      "Score: 0.7003459\n",
      "연번: 51\n",
      "학과명: 인공지능학과\n",
      "교수명: 김한준\n",
      "논문명: A Tensor Space Model-Based Deep Neural Network for Text Classification\n",
      "초록_요약: \n",
      "텍스트 분류에 일반적으로 사용되는 머신러닝 알고리즘 중 나이브 베이즈 및 서포트 벡터 머신은 합리적인 성능을 제공하지만, 딥 러닝을 활용한 텍스트 분류는 이전 알고리즘에 비해 큰 성능 향상을 보이지 않았다. 본 연구에서는 의미적 텐서 공간 모델을 기반으로 한 개념 중심의 딥 뉴럴 네트워크를 제안하여 텍스트의 내재된 의미 정보 손실 문제를 극복하고, 이를 통해 기존 및 최근 학습 방법보다 우수한 성능을 달성했다.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Row 4:\n",
      "Score: 0.69677114\n",
      "연번: 61\n",
      "학과명: 인공지능학과\n",
      "교수명: 최호식\n",
      "논문명: Primal path algorithm for compositional data analysis\n",
      "초록_요약: 논문에서는 공분포 데이터에 대한 LASSO(Least Absolute Shrinkage and Selection Operator) 추정기를 개발하였습니다. 이는 회귀 계수에 대한 선형 제약 조건을 고려하여 효율적인 정규화 회귀 모델을 제공하며, 이를 통해 고차원 데이터에서의 빠른 계산과 정확한 회귀 분석이 가능합니다. 논문에서 제안된 알고리즘은 경제학과 생물학 분야의 실제 데이터에 적용되어, 기존의 LASSO 알고리즘보다 더 효율적인 결과를 도출하였습니다.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Row 5:\n",
      "Score: 0.68691015\n",
      "연번: 56\n",
      "학과명: 인공지능학과\n",
      "교수명: 유하진\n",
      "논문명: Regularized Within-Class Precision Matrix Based PLDA in Text-Dependent Speaker Verification\n",
      "초록_요약: 이 연구에서는 기존의 화자 확인 모델인 확률적 선형 판별 분석(PLDA)을 개선하기 위해 정규화된 클래스 내 정밀도 행렬을 도입한 방법을 제안합니다. 이를 통해 GLASSO 정규화를 활용하여 추정 오차를 감소시키며, 텍스트 의존적 화자 확인 실험에서 상대적인 등가 오류율을 최대 23%까지 감소시켰습니다\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = 'jhgan__ko-sbert-sts'\n",
    "\n",
    "q = \"희소한 해를 찾기위한 회귀모형\"\n",
    "\n",
    "search_result = es.search(index = \"embeddings\", knn={\n",
    "    \"field\": \"text_embedding.predicted_value.predicted_value\",\n",
    "    \"query_vector_builder\": {\n",
    "        \"text_embedding\": {\n",
    "            \"model_id\": model_id,\n",
    "            \"model_text\": f\"query: {q}\",\n",
    "        }\n",
    "    },\n",
    "    \"k\": 5, \n",
    "    \"num_candidates\": 10\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "hits = search_result.get('hits', {}).get('hits', [])\n",
    "\n",
    "for i, hit in enumerate(hits, 1):\n",
    "    source = hit.get('_source', {})\n",
    "    print(f\"Row {i}:\")\n",
    "    # print(f\"Document ID: {hit['_id']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"연번: {source['연번']}\")\n",
    "    print(f\"학과명: {source['학과명']}\")\n",
    "    print(f\"교수명: {source['교수명']}\")\n",
    "    print(f\"논문명: {source['논문명']}\")\n",
    "    print(f\"초록_요약: {source['초록_요약']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색할 쿼리 설정 (예: 모든 문서 검색)\n",
    "# query = {\n",
    "#     \"query\": {\n",
    "#         \"multi_match\": {\n",
    "#             \"query\": text,\n",
    "#             \"fields\": [\"*\"]\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "q = \"희소한 해를 찾기위한 회귀모형\"\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"초록_요약\": f'{q}'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 인덱스에서 데이터 검색\n",
    "search_results = es.search(index = 'embeddings', body=query, size = 10)\n",
    "\n",
    "es_list = []\n",
    "# 검색 결과 출력\n",
    "for hit in search_results['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    score = hit['_score']\n",
    "    print(f\"Score: {score}, {source}\")\n",
    "    es_list.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제_키워드</th>\n",
       "      <th>교수명</th>\n",
       "      <th>논문_키워드</th>\n",
       "      <th>연구_키워드</th>\n",
       "      <th>특허_키워드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>okvgQowBbDgh3QVNHzQi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>강인혜</td>\n",
       "      <td>NaN</td>\n",
       "      <td>인공지능</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o0vgQowBbDgh3QVNHzQi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>권원태</td>\n",
       "      <td>NaN</td>\n",
       "      <td>자동화</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pEvgQowBbDgh3QVNHzQi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김상주</td>\n",
       "      <td>NaN</td>\n",
       "      <td>분역스위칭</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pUvgQowBbDgh3QVNHzQi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김태현</td>\n",
       "      <td>NaN</td>\n",
       "      <td>임베디드 시스템</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pkvgQowBbDgh3QVNHzQi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>나영승</td>\n",
       "      <td>NaN</td>\n",
       "      <td>연료전지</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X0vgQowBbDgh3QVNHzYi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김정식</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>압력 센서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XEvgQowBbDgh3QVNHzYi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김정식</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>스트레인 게이지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XUvgQowBbDgh3QVNHzYi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김정식</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>광촉매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XkvgQowBbDgh3QVNHzYi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김정식</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>압력센서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEvgQowBbDgh3QVNHzYi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>김정식</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>실리콘 웨이퍼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<p>447 rows × 5 columns</p>"
      ],
      "text/plain": [
       "                     과제_키워드  교수명 논문_키워드    연구_키워드    특허_키워드\n",
       "okvgQowBbDgh3QVNHzQi    NaN  강인혜    NaN      인공지능       NaN\n",
       "o0vgQowBbDgh3QVNHzQi    NaN  권원태    NaN       자동화       NaN\n",
       "pEvgQowBbDgh3QVNHzQi    NaN  김상주    NaN     분역스위칭       NaN\n",
       "pUvgQowBbDgh3QVNHzQi    NaN  김태현    NaN  임베디드 시스템       NaN\n",
       "pkvgQowBbDgh3QVNHzQi    NaN  나영승    NaN      연료전지       NaN\n",
       "...                     ...  ...    ...       ...       ...\n",
       "X0vgQowBbDgh3QVNHzYi    NaN  김정식    NaN       NaN     압력 센서\n",
       "XEvgQowBbDgh3QVNHzYi    NaN  김정식    NaN       NaN  스트레인 게이지\n",
       "XUvgQowBbDgh3QVNHzYi    NaN  김정식    NaN       NaN       광촉매\n",
       "XkvgQowBbDgh3QVNHzYi    NaN  김정식    NaN       NaN      압력센서\n",
       "YEvgQowBbDgh3QVNHzYi    NaN  김정식    NaN       NaN   실리콘 웨이퍼\n",
       "\n",
       "[447 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = ed.DataFrame(es, es_index_pattern = \"graph\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot():\n",
    "    def __init__(self, model='gpt-4.0'):\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "        self.max_context_length = 8000\n",
    "\n",
    "    def ask(self, question):\n",
    "        if len(question) > self.max_context_length:\n",
    "            question = question[:self.max_context_length]\n",
    "\n",
    "        self.messages.append({\n",
    "            'role': 'user', \n",
    "            'content': question\n",
    "        })\n",
    "        res = self.__ask__()\n",
    "        return res\n",
    "        \n",
    "    def __ask__(self):\n",
    "        my_messages = self.messages\n",
    "        if len(self.messages) > self.max_context_length:\n",
    "            my_messages = self.messages[:self.max_context_length]\n",
    "            \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            # model 지정\n",
    "            model=self.model,\n",
    "            messages=my_messages\n",
    "        )\n",
    "        response = completion.choices[0].message['content']\n",
    "        self.messages.append({\n",
    "            'role': 'assistant', \n",
    "            'content': response\n",
    "        })\n",
    "        return response\n",
    "    \n",
    "    def show_messages(self):\n",
    "        return self.messages\n",
    "    \n",
    "    def clear(self):\n",
    "        self.messages.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'마르코프 랜덤 필드 혹은 GM는 복잡한 상관관계를 직관적으로 표현해주는 그래프를 제공하기에 다양한 분야에서 활용된다. 그러나 숫자 데이터는 과도한 분산을 보이는데, 이를 제대로 반영하지 못하는 문제가 있다. 본 연구에서는 이에 대한 해결책으로 '과도한 0'을 가진 과분산 계수 데이터에 대한 그래픽 모델로 NB 그래픽 모델을 제안한다.'\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = ChatBot(model='gpt-4')\n",
    "input = \"\"\"\n",
    "        Markov random field or undirected graphical models (GM) are a popular class of GM useful in various fields because they provide an intuitive and interpretable graph expressing the complex relationship between random variables. The zero-inflated local Poisson graphical model has been proposed as a graphical model for count data with excess zeros. However, as count data are often characterized by over-dispersion, the local Poisson graphical model may suffer from a poor fit to data. In this paper, we propose a zero-inflated local negative binomial (NB) graphical model. Due to the dependencies of parameters in our models, a direct optimization of the objective function is difficult. Instead, we devise expectation-minimization algorithms based on two different parametrizations for the NB distribution. Through a simulation study, we illustrate the effectiveness of our method for learning network structure from over-dispersed count data with excess zeros. We further apply our method to real data to estimate its network structure.\n",
    "        \"\"\"\n",
    "text = chatbot.ask(f\"\"\"\n",
    "                   나는 현재 통계학 분야의 논문의 초록을 '논문이 어떤 연구를 했는지 가장 잘 나타내는 문장'으로 요약할 것이다.\n",
    "                   아래의 초록을 요약하는데 다음의 다섯가지 기준을 반영해줘.\n",
    "                   1. 영어 약자와 특수문자는 반드시 한국어 용어로 바꿔줘. \n",
    "                   2. simulation과 result이후 내용은 제외해줘. \n",
    "                   3. propose가 들어간 문장을 중점으로 연구 내용과 목적이 자세하게 드러나게 해줘.\n",
    "                   4. 한국어로 답변해줘 ('-다' 체 구사).\n",
    "                   5. 답변은 반드시 한국어 100자 이내로 해줘.\n",
    "                   초록: '{input}'\n",
    "                   \"\"\") \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>교수명</th>\n",
       "      <th>키워드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [교수명, 키워드]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 빈 데이터프레임 생성\n",
    "columns = ['교수명', '키워드']\n",
    "new_data_df = pd.DataFrame(columns=columns)\n",
    "new_data_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_2580\\4226681944.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data_df = new_data_df.append(new_data, ignore_index=True)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for gpt-4 in organization org-eUkXeByS8EGMSSCQuyUy3B7n on tokens_usage_based per min: Limit 10000, Used 9909, Requested 294. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jieun\\Desktop\\project\\elastic\\code\\eland.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     chatbot \u001b[39m=\u001b[39m ChatBot(model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     kwd \u001b[39m=\u001b[39m chatbot\u001b[39m.\u001b[39;49mask(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m                       데이터: \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mrow\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m                       \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m연구영역\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m에서 이 연구자의 연구영역을 가장 잘 나타내는 키워드를 \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m한글단어 한 개\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m로 추출해줘.\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m                       \u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     new_data \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39m교수명\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39m교수명\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m키워드\u001b[39m\u001b[39m'\u001b[39m: kwd}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     new_data_df \u001b[39m=\u001b[39m new_data_df\u001b[39m.\u001b[39mappend(new_data, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\jieun\\Desktop\\project\\elastic\\code\\eland.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     question \u001b[39m=\u001b[39m question[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_context_length]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: question\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m })\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__ask__()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[1;32mc:\\Users\\jieun\\Desktop\\project\\elastic\\code\\eland.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessages) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_context_length:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     my_messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessages[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_context_length]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# model 지정\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     messages\u001b[39m=\u001b[39;49mmy_messages\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m response \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: response\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/eland.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\jieun\\anaconda3\\envs\\eland\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\jieun\\anaconda3\\envs\\eland\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\jieun\\anaconda3\\envs\\eland\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\jieun\\anaconda3\\envs\\eland\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jieun\\anaconda3\\envs\\eland\\lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for gpt-4 in organization org-eUkXeByS8EGMSSCQuyUy3B7n on tokens_usage_based per min: Limit 10000, Used 9909, Requested 294. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/연구자.csv')\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    chatbot = ChatBot(model='gpt-4')\n",
    "    kwd = chatbot.ask(f\"\"\"\n",
    "                       데이터: '{row}'\n",
    "                       '연구영역'에서 이 연구자의 연구영역을 가장 잘 나타내는 키워드를 '한글단어 한 개'로 추출해줘.\n",
    "                       \"\"\")\n",
    "    new_data = {'교수명': row['교수명'], '키워드': kwd}\n",
    "    new_data_df = new_data_df.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>교수명</th>\n",
       "      <th>키워드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강인혜</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>권원태</td>\n",
       "      <td>'자동화'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김상주</td>\n",
       "      <td>'분역스위칭'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>김태현</td>\n",
       "      <td>임베디드 시스템</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나영승</td>\n",
       "      <td>연료전지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>문영일</td>\n",
       "      <td>'수자원'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>박도원</td>\n",
       "      <td>'암석역학'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>이준규</td>\n",
       "      <td>지반공학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>조수진</td>\n",
       "      <td>스마트구조기술</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>조용준</td>\n",
       "      <td>해안</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    교수명       키워드\n",
       "0   강인혜      인공지능\n",
       "1   권원태     '자동화'\n",
       "2   김상주   '분역스위칭'\n",
       "3   김태현  임베디드 시스템\n",
       "4   나영승      연료전지\n",
       "..  ...       ...\n",
       "74  문영일     '수자원'\n",
       "75  박도원    '암석역학'\n",
       "76  이준규      지반공학\n",
       "77  조수진   스마트구조기술\n",
       "78  조용준        해안\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_df.to_csv('../data/연구자그래프.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     교수명    연구_키워드 논문_키워드 과제_키워드  특허_키워드\n",
      "0    강인혜      인공지능    NaN    NaN     NaN\n",
      "1    권원태     '자동화'    NaN    NaN     NaN\n",
      "2    김상주   '분역스위칭'    NaN    NaN     NaN\n",
      "3    김태현  임베디드 시스템    NaN    NaN     NaN\n",
      "4    나영승      연료전지    NaN    NaN     NaN\n",
      "..   ...       ...    ...    ...     ...\n",
      "658  박병은       NaN    NaN    NaN  '태양전지'\n",
      "659  박병은       NaN    NaN    NaN  소음 방지재\n",
      "660  박병은       NaN    NaN    NaN    태양전지\n",
      "661  박병은       NaN    NaN    NaN     프린터\n",
      "662  박병은       NaN    NaN    NaN     프린터\n",
      "\n",
      "[663 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "연구자_df = pd.read_csv('../data/연구자그래프.csv')\n",
    "논문_df = pd.read_csv('../data/논문그래프.csv')\n",
    "과제_df = pd.read_csv('../data/과제그래프.csv')\n",
    "특허_df = pd.read_csv('../data/특허그래프.csv')\n",
    "\n",
    "연구자_df.columns = ['교수명', '연구_키워드']\n",
    "논문_df.columns = ['교수명', '논문_키워드']\n",
    "과제_df.columns = ['교수명', '과제_키워드']\n",
    "특허_df.columns = ['교수명', '특허_키워드']\n",
    "\n",
    "# 데이터프레임들을 행으로 연결\n",
    "전체_df = pd.concat([연구자_df, 논문_df, 과제_df, 특허_df], ignore_index=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(전체_df)\n",
    "\n",
    "\n",
    "전체_df.to_csv('../data/그래프연습.csv', encoding='utf-16', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
