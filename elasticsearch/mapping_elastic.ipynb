{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "!pip install -U torch transformers tokenizers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM\n",
    "\n",
    "MODEL = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\", non_blocking=True)\n",
    "model.eval()\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text-generation', \n",
    "    model=model,\n",
    "    tokenizer=MODEL,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "def ask(x, context='', is_input_full=False):\n",
    "    ans = pipe(\n",
    "        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\", \n",
    "        do_sample=True, \n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_full_text=False,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(ans[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "from elasticsearch.helpers import reindex\n",
    "# import openai\n",
    "# requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jieun\\\\Desktop\\\\project\\\\elastic'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('c:\\\\Users\\\\jieun\\\\Desktop\\\\project\\\\elastic')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': '172.16.204.219', 'port': 9200, 'use_ssl': True}])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch('https://172.16.204.219:9200', http_auth=['jieun','jieun123'], verify_certs=False)\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업로드 성공: 2065, 업로드 실패: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# with open('data/doc2_실시간도착_역정보(20230828).csv', 'rt', encoding='utf-8') as f:\n",
    "#   print(f.read())\n",
    "# #   fieldnames = ['search_string', 'sort']\n",
    "#   reader = csv.DictReader(f)\n",
    "#   helpers.bulk(es, reader, index='my-index2')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "csv_file_path = '../data/tmp_fulltext.csv'  # 업로드할 CSV 파일의 경로를 지정하세요.\n",
    "index_name = \"fulltext-db\"\n",
    "\n",
    "# CSV 파일을 Pandas DataFrame으로 읽기\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# DataFrame을 JSON 형식으로 변환 (각 행을 JSON 객체로 변환)\n",
    "documents = df.to_dict(orient='records')\n",
    "\n",
    "# Bulk API 요청 생성\n",
    "bulk_data = []\n",
    "for document in documents:\n",
    "    # 각 문서를 인덱스와 타입과 함께 설정\n",
    "    action = {\n",
    "        \"_index\": index_name,  # Elasticsearch 인덱스 이름을 지정하세요.\n",
    "        \"_source\": document\n",
    "    }\n",
    "    bulk_data.append(action)\n",
    "\n",
    "# Bulk API를 사용하여 데이터 업로드\n",
    "success, failed = helpers.bulk(es, bulk_data, index = index_name, raise_on_error=False)\n",
    "\n",
    "print(f\"업로드 성공: {success}, 업로드 실패: {failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".security-7\n",
      "byte-image-index\n",
      "rules\n",
      "rules_folder\n",
      ".kibana_task_manager_1\n",
      ".apm-agent-configuration\n",
      ".kibana_1\n",
      "fulltext-db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "index_list = es.indices.get_alias().keys()\n",
    "for index in index_list:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fulltext-db': {'mappings': {'properties': {'document': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 인덱스의 매핑 정보 가져오기\n",
    "mapping_info = es.indices.get_mapping(index = index_name)\n",
    "\n",
    "# 매핑 정보 출력\n",
    "print(mapping_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\pykg2vec\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use the 'settings' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제거할 토크나이저 이름 지정\n",
    "tokenizer_name_to_remove = \"nori_sample\"  # 제거하려는 토크나이저 이름을 설정하세요\n",
    "index_name = \"my-index2\"  # 인덱스 이름을 적절히 변경하세요\n",
    "\n",
    "# 인덱스를 닫습니다.\n",
    "es.indices.close(index=index_name)\n",
    "\n",
    "# 토크나이저를 포함한 설정에서 토크나이저를 제거합니다.\n",
    "tokenizer_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                tokenizer_name_to_remove: None  # 토크나이저를 제거하려면 None으로 설정합니다.\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 설정 업데이트\n",
    "es.indices.put_settings(index=index_name, body=tokenizer_settings)\n",
    "\n",
    "# 인덱스를 다시 엽니다.\n",
    "es.indices.open(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 '연구분야추가' 삭제 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 삭제할 인덱스 이름 지정\n",
    "index_name = \"연구분야추가\"  # 삭제하려는 인덱스 이름을 설정하세요\n",
    "\n",
    "# 인덱스 삭제 명령 실행\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"인덱스 '{index_name}' 삭제 완료\")\n",
    "else:\n",
    "    print(f\"인덱스 '{index_name}'는 이미 존재하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': \"공과대학 기계정보공학과 김태현교수가 주관하는 연구는 2020에 농촌진흥청에서 주최하는 'IoT 기술을 이용한 최첨단 제어시설 확립을 위한 계획 수립안 제시'에 대한 연구이다. 이 연구는 물리/기계 측정표준에서 환경에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 김태현교수가 주관하는 연구는 2022-2023에 과학기술정보통신부에서 주최하는 '개방형 IoT·엣지 컴퓨팅 환경 기반 딥러닝 융합 오픈 소스 지능형 고장 진단 시스템 개발'에 대한 연구이다. 이 연구는 임베디드 S/W에서 제조업(전자부품, 컴퓨터, 영상, 음향 및 통신장비)에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 나영승교수가 주관하는 연구는 2020-2022에 과학기술정보통신부에서 주최하는 '고분자 전해질막 수전해 분리판 유로 및 확산체 설계'에 대한 연구이다. 이 연구는 유체기계에서 기타 산업에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 이광훈교수가 주관하는 연구는 2021에 과학기술정보통신부에서 주최하는 'X-TWICE 실전문제연구단'에 대한 연구이다. 이 연구는 S/W 솔루션에서 교육 및 인력양성에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 이광훈교수가 주관하는 연구는 2020에 교육부에서 주최하는 '대학혁신지원(R&D)'에 대한 연구이다. 이 연구는 과학기술과 인문사회에서 지식의 진보(비목적 연구)에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 이광훈교수가 주관하는 연구는 2020에 농촌진흥청에서 주최하는 '재생에너지 이용 및 자원의 순환을 통한 에너지 자립형 둔방형 첨단 R&BD 센터 운영안'에 대한 연구이다. 이 연구는 물리/기계 측정표준에서 환경에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 이광훈교수가 주관하는 연구는 2022-2023에 과학기술정보통신부에서 주최하는 '폐합성목재 촉매열처리공정을 통한 수소 및 액상 연료 합성'에 대한 연구이다. 이 연구는 폐기물 자원화기술에서 환경에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 이광훈교수가 주관하는 연구는 2020-2021에 과학기술정보통신부에서 주최하는 '표면 집중 존재 금속 촉매를 이용한 효율적인 폐플라스틱 열화학적 촉매전환공정'에 대한 연구이다. 이 연구는 폐기물 자원화기술에서 하수,폐기물처리, 원료재생 및 환경복원업에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 기계정보공학과 황면중교수가 주관하는 연구는 2021에 과학기술정보통신부에서 주최하는 '유연한 작업물의 안정적인 이송을 위한 로봇의 모션 제어 연구'에 대한 연구이다. 이 연구는 로봇 제어/지능화기술에서 제조업(전기 및 기계장비)에 적용될 수 있다.\"}\n",
      "{'document': \"공과대학 신소재공학과 김상일교수가 주관하는 연구는 2022에 과학기술정보통신부에서 주최하는 'FeS2-FeSe2-FeTe2 철계 칼코게나이드 소재 시스템의 열전 물성 연구'에 대한 연구이다. 이 연구는 광/전자세라믹스에서 제조업(전기 및 기계장비)에 적용될 수 있다.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 검색할 쿼리 설정 (예: 모든 문서 검색)\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 인덱스에서 데이터 검색\n",
    "search_results = es.search(index = index_name, body=query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for hit in search_results['hits']['hits']:\n",
    "    print(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # 노리 토크나이저 및 필터 설정\n",
    "# def configure_nori_tokenizer():\n",
    "#     # 노리 토크나이저 및 필터 설정\n",
    "#     tokenizer_settings = {\n",
    "#         \"settings\": {\n",
    "#             \"analysis\": {\n",
    "#                 \"tokenizer\": {\n",
    "#                     \"my_nori_tokenizer\": {\n",
    "#                         \"type\": \"nori_tokenizer\",\n",
    "#                         \"decompound_mode\": \"mixed\"\n",
    "#                         # \"user_dictionary\": \"userdict_ko.txt\"\n",
    "#                     }\n",
    "#                 },\n",
    "#                 \"analyzer\": {\n",
    "#                     \"my_nori_analyzer\": {\n",
    "#                         \"type\": \"custom\",\n",
    "#                         \"tokenizer\": \"my_nori_tokenizer\",\n",
    "#                         \"filter\": [\"my_shingle\"]\n",
    "#                     }\n",
    "#                 },\n",
    "#                 \"filter\": {\n",
    "#                     \"my_shingle\": {\n",
    "#                         \"type\": \"shingle\",\n",
    "#                         \"token_separator\": \"\",\n",
    "#                         \"max_shingle_size\": 2\n",
    "#                     }\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "#     # 매핑에 노리 분석기 적용\n",
    "#     es.indices.close(index=\"fulltext_db\")  # 인덱스를 닫음 (인덱스를 수정하기 위해 필요)\n",
    "    \n",
    "#     # 설정 업데이트\n",
    "#     es.indices.put_settings(index=\"fulltext_db\", body=tokenizer_settings)\n",
    "    \n",
    "#     es.indices.open(index=\"fulltext_db\")  # 인덱스를 다시 열음\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     configure_nori_tokenizer()  # 노리 토크나이저 및 필터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\jieun\\anaconda3\\envs\\elastic\\lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '172.16.204.219'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(226, [])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "## ES에 데이터 올리는 코드 ##\n",
    "###########################\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "# data_path = \"data/\"\n",
    "# csv_files = os.listdir(data_path)\n",
    "# dataframes = [pd.read_csv(data_path + file) for file in csv_files]\n",
    "# print(csv_files)\n",
    "\n",
    "df = pd.read_csv('C:/Users/jieun/Desktop/project/elastic/data/연구분야추가2.csv')\n",
    "df = df.fillna(0)\n",
    "index_name = \"연구분야추가2\"\n",
    "\n",
    "field_name = df.columns.to_list()\n",
    "f_type = df.dtypes\n",
    "\n",
    "# Define a custom analyzer\n",
    "custom_analyzer = {\n",
    "    \"tokenizer\": \"my_tokenizer\",\n",
    "    \"filter\": [\"lowercase\", \"trim\", \"stop\", \"my_filter\", \"nori_filter\"]\n",
    "    # \"char_filter\": [\"html_strip\"]\n",
    "}\n",
    "\n",
    "# Define a custom filter for the analyzer\n",
    "custom_filter = {\n",
    "    \"type\": \"pattern_replace\",\n",
    "    \"pattern\": \"[^a-zA-Z0-9가-힣\\\\s]\",\n",
    "    \"replacement\": \" \"\n",
    "}\n",
    "\n",
    "# Define a custom tokenizer\n",
    "custom_tokenizer = {\n",
    "    \"type\": \"nori_tokenizer\",\n",
    "    \"decompound_mode\": \"mixed\",\n",
    "    \"discard_punctuation\": False\n",
    "}\n",
    "\n",
    "# nori 토큰 필터 설정\n",
    "nori_filter = {\n",
    "    \"type\": \"nori_part_of_speech\",\n",
    "    \"stoptags\": [\"E\", \"IC\", \"J\", \"MAG\", \"MAJ\", \"MM\", \"SP\", \"SSC\", \"SSO\", \"SC\", \"SE\", \"XPN\", \"XSA\", \"XSN\", \"XSV\", \"UNA\", \"NA\", \"VSV\"]\n",
    "}\n",
    "\n",
    "# Create an index with custom analyzer and tokenizer settings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"my_analyzer\": custom_analyzer\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"my_filter\": custom_filter,\n",
    "                \"nori_filter\": nori_filter\n",
    "            },\n",
    "            \"tokenizer\": {\n",
    "                \"my_tokenizer\": custom_tokenizer\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {}  # We'll add the properties dynamically\n",
    "    }\n",
    "}\n",
    "\n",
    "# Iterate through the dataframes and dynamically add properties to the mappings\n",
    "# for df in dataframes:\n",
    "fields = df.columns.tolist()\n",
    "\n",
    "for field in fields:\n",
    "    field_type = \"text\" if pd.api.types.is_string_dtype(df[field]) or pd.api.types.is_object_dtype(df[field]) else \"long\"\n",
    "    if field_type == \"text\":\n",
    "        index_settings[\"mappings\"][\"properties\"][field] = {\"type\": field_type, \"analyzer\": \"my_analyzer\"}\n",
    "    else:\n",
    "        index_settings[\"mappings\"][\"properties\"][field] = {\"type\": field_type}\n",
    "\n",
    "index_settings[\"mappings\"]\n",
    "\n",
    "# Create the index with the defined settings\n",
    "es.indices.create(index = index_name, body = index_settings)\n",
    "\n",
    "# Bulk insert data into Elasticsearch\n",
    "actions = []\n",
    "for _, row in df.iterrows():\n",
    "    data = row.to_dict()\n",
    "    actions.extend([{\"_index\": index_name, \"_source\": data}])\n",
    "\n",
    "helpers.bulk(es, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\pykg2vec\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use the 'settings' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nori 토크나이저가 'my-index' 인덱스에 적용되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 이름 설정\n",
    "index_name = '과제'  # 기존 인덱스 이름을 지정하세요.\n",
    "\n",
    "# 인덱스에 Nori 토크나이저와 분석기 설정 적용\n",
    "es.indices.close(index=index_name)  # 인덱스를 닫아야 설정을 변경할 수 있습니다.\n",
    "es.indices.put_settings(body=nori_settings, index=index_name)\n",
    "es.indices.open(index=index_name)  # 인덱스를 다시 열어 설정을 적용합니다.\n",
    "\n",
    "print(f\"Nori 토크나이저가 '{index_name}' 인덱스에 적용되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\ufeff호선': '02호선', '상/하행선': '2', '요일': '2', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '235100', '막차출발역코드': '211', '막차도착역코드': '234', '막차출발역명': '성수', '막차도착역명': '신도림'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '1', '요일': '3', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '234900', '막차출발역코드': '211', '막차도착역코드': '202', '막차출발역명': '성수', '막차도착역명': '을지로입구'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '2', '요일': '1', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '245000', '막차출발역코드': '211', '막차도착역코드': '234', '막차출발역명': '성수', '막차도착역명': '신도림'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '1', '요일': '2', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '234900', '막차출발역코드': '211', '막차도착역코드': '202', '막차출발역명': '성수', '막차도착역명': '을지로입구'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '2', '요일': '3', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '235100', '막차출발역코드': '211', '막차도착역코드': '234', '막차출발역명': '성수', '막차도착역명': '신도림'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '1', '요일': '1', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '244900', '막차출발역코드': '211', '막차도착역코드': '202', '막차출발역명': '성수', '막차도착역명': '을지로입구'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '2', '요일': '2', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '235100', '막차출발역코드': '211', '막차도착역코드': '234', '막차출발역명': '성수', '막차도착역명': '신도림'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '1', '요일': '3', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '234900', '막차출발역코드': '211', '막차도착역코드': '202', '막차출발역명': '성수', '막차도착역명': '을지로입구'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '2', '요일': '1', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '245000', '막차출발역코드': '211', '막차도착역코드': '234', '막차출발역명': '성수', '막차도착역명': '신도림'}\n",
      "{'\\ufeff호선': '02호선', '상/하행선': '1', '요일': '2', '전철역코드': '239', '외부코드': '239', '전철역명': '홍대입구', '첫차시간': '53000', '첫차출발역코드': '239', '첫차도착역코드': '211', '첫차출발역명': '홍대입구', '첫차도착역명': '성수', '막차시간': '234900', '막차출발역코드': '211', '막차도착역코드': '202', '막차출발역명': '성수', '막차도착역명': '을지로입구'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\pykg2vec\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "# 검색할 쿼리 설정\n",
    "search_query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"전철역명\": \"홍대입구\"  # 필드 이름과 검색어를 적절하게 수정하세요.\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Elasticsearch에서 인덱스 검색 실행\n",
    "index_name = 'fulltext-db'\n",
    "search_results = es.search(index=index_name, body=search_query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for hit in search_results['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nori 토큰화 결과: 남부터미널\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\pykg2vec\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# # 예제 데이터 생성\n",
    "# example_text = \"엘라스틱서치는 고성능 오픈소스 분산 검색 및 분석 엔진입니다.\"\n",
    "# example_data = {\"text\": example_text}\n",
    "\n",
    "# # 인덱스 이름 설정 (이전 예제에서 설정한 인덱스 이름을 사용하세요.)\n",
    "# index_name = 'index-testing'\n",
    "\n",
    "# # 예제 데이터를 Elasticsearch에 색인화\n",
    "# es.index(index=index_name, body=example_data)\n",
    "\n",
    "# Elasticsearch에서 Nori 토크나이저 및 분석기를 사용하여 분석 결과 확인\n",
    "analysis_request = {\n",
    "    \"text\": '남부터미널'\n",
    "}\n",
    "\n",
    "analysis_result = es.indices.analyze(index=index_name, body=analysis_request)\n",
    "\n",
    "# 분석 결과 출력\n",
    "tokens = [token['token'] for token in analysis_result['tokens']]\n",
    "# print(\"원본 텍스트:\", example_text)\n",
    "print(\"Nori 토큰화 결과:\", \" \".join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'token': '남부터미널', 'start_offset': 0, 'end_offset': 5, 'type': '<HANGUL>', 'position': 0}]\n"
     ]
    }
   ],
   "source": [
    "print(analysis_result['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nori+tokenizer를 이용한 한글 형태소 분석하기\n",
    "/*\n",
    " * [인덱스 생성 및 설정]\n",
    "*/\n",
    "PUT nori_sample\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index\": {\n",
    "      // elasticsearch에서 기본 제공하는 설정, 색인에 대한 분석 구성을 정의한다.\n",
    "      \"analysis\": {\n",
    "        // 색인에 대한 토크나이저를 구성한다.\n",
    "        \"tokenizer\": {\n",
    "          \"my_nori_tokenizer\": {\n",
    "            \"type\": \"nori_tokenizer\",\n",
    "            \"decompound_mode\": \"mixed\", // 'mixed' 복합 명사를 분해하는 기능을 수행\n",
    "            \"discard_punctuation\": \"false\" // 문장 부호 제거하지 않도록 설정한다. (기본적으로 제거한다.)\n",
    "          }\n",
    "        },\n",
    "        // analyzer는 분할된 토큰에 필터링과 정규화 처리 통헤 섹인에 추가할 단어의 집합을 만드는 데 사용된다.\n",
    "        \"analyzer\": {\n",
    "          // analyzer를 여러 개 만들어서 사용 가능하다.\n",
    "          \"my_nori_analyzer\": {\n",
    "            \"type\": \"custom\",\n",
    "            \"tokenizer\": \"my_nori_tokenizer\", \n",
    "            // lowercase: 알파벳 소문자로 통일 시킨다.\n",
    "            // stop: 문서에서 자주 사용되는 불용어를 제거한다.(검색 품질 향상: \"the\", \"a\", \"an\", \"and\" 와 같은 단어 검색에서 제외)\n",
    "            \"filter\": [\"lowercase\", \"stop\"],\n",
    "            // html_strip: HTML 태그 제거\n",
    "            \"char_filter\": [\"html_strip\"]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mappings\" : {\n",
    "    \"properties\" : {\n",
    "      \"title\": {\n",
    "        \"type\" : \"text\",\n",
    "        \"analyzer\": \"my_nori_analyzer\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET nori_sample/_analyze\n",
    "{\n",
    "  \"tokenizer\": \"my_nori_tokenizer\",\n",
    "  \"text\": [\n",
    "    \"동해물과 백두산이\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "# 엘라스틱서치에는 여러개의 필드타입이 존재하는데요 text 타입일때 analyzer를 통한 fulltext 검색이 가능합니다\n",
    "# 흔히 text와 keyword 타입의 차이가 뭐지라는 질문이 있는데요\n",
    "# text는 풀텍스트 서치가 필요한 텍스트,\n",
    "# keyword는 구조화된 텍스트, 예를들면 ID나 이메일, 우편번호같이 풀텍스트 서치가 필요없는 필드를 지정할때 쓰시면 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 인덱스의 매핑 가져오기\n",
    "GET /doc1/_mapping\n",
    "\n",
    "# \n",
    "PUT /_template/nori_template\n",
    "{\n",
    "  \"index_patterns\": [\"doc1\", \"doc2\"],\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"nori_sample_analyzer\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"nori_tokenizer\"\n",
    "        }\n",
    "      },\n",
    "      \"tokenizer\": {\n",
    "        \"nori_tokenizer\": {\n",
    "          \"type\": \"nori_tokenizer\",\n",
    "          \"decompound_mode\": \"mixed\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieun\\anaconda3\\envs\\pykg2vec\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'dictionary'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search_app/setting_bulk.py   # 여기에 구현\n",
    "# 인덱스 생성\n",
    "es.indices.create( \n",
    "    index='dictionary',  # 인덱스 이름: dictionary\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"index\": { \n",
    "                \"analysis\": {\n",
    "                    \"analyzer\": {  # 애널라이저 put\n",
    "                        \"my_analyzer\": {  # 애널라이저 이름\n",
    "                            \"type\": \"custom\",\n",
    "                            \"tokenizer\": \"nori_tokenizer\"  # 노리 적용\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_app/setting_bulk.py   # 여기에 구현\n",
    "# 매핑 설정 (인덱스에 들어가는 데이터의 타입을 정의. 자동으로 만들어주는 것보다 지정하는 것을 권장.)\n",
    "es.indices.create(\n",
    "    index='dictionary',  # dictionary 인덱스에\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"index\": {\n",
    "                \"analysis\": {\n",
    "                    \"analyzer\": {\n",
    "                        \"my_analyzer\": {\n",
    "                            \"type\": \"custom\",\n",
    "                            \"tokenizer\": \"nori_tokenizer\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {  # 매핑을 설정\n",
    "            \"dictionary_datas\": {\n",
    "                \"properties\": {\n",
    "                    \"id\": {\n",
    "                        \"type\": \"long\"\n",
    "                    },\n",
    "                    \"title\": {\n",
    "                        \"type\": \"text\",  # 타입 텍스트로 지정\n",
    "                        \"analyzer\": \"my_analyzer\"\n",
    "                    },\n",
    "                    \"content\": {\n",
    "                        \"type\": \"text\",  # 타입 텍스트로 지정\n",
    "                        \"analyzer\": \"my_analyzer\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dictionary_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_66540\\4184880034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dictionary_data.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dictionary_data.json'"
     ]
    }
   ],
   "source": [
    "# search_app/setting_bulk.py\n",
    "# bulk json version\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open(\"dictionary_data.json\", encoding='utf-8') as json_file:\n",
    "#     json_data = json.loads(json_file.read())\n",
    "\n",
    "# body = \"\"\n",
    "# for i in json_data:\n",
    "#     body = body + json.dumps({\"index\": {\"_index\": \"dictionary\", \"_type\": \"dictionary_datas\"}}) + '\\n'\n",
    "#     body = body + json.dumps(i, ensure_ascii=False) + '\\n'\n",
    "\n",
    "# es.bulk(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rest_framework'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_66540\\2581188271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# search_app/views.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 클래스 기반 뷰\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrest_framework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviews\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAPIView\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrest_framework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrest_framework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rest_framework'"
     ]
    }
   ],
   "source": [
    "# search_app/views.py\n",
    "search_word = request.query_params.get('search')\n",
    "\n",
    "if not search_word:\n",
    "    return Response(status=status.HTTP_400_BAD_REQUEST, data={'message': 'search word param is missing'})\n",
    "\n",
    "docs = es.search(index='dictionary',\n",
    "                    doc_type='dictionary_datas',\n",
    "                    body={\n",
    "                        \"query\": {\n",
    "                            \"multi_match\": {\n",
    "                                \"query\": search_word,\n",
    "                                \"fields\": [\"title\", \"content\"]\n",
    "                            }\n",
    "                        }\n",
    "                    })\n",
    "\n",
    "data_list = docs['hits']\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement rest_framework (from versions: none)\n",
      "ERROR: No matching distribution found for rest_framework\n"
     ]
    }
   ],
   "source": [
    "# server_project/urls.py\n",
    "# uri 설정. url의 설정한 부분까지 잘라내고 남은 문자열 부분의 후속 처리를 위해 search_app의 urls.py와 연결해줍니다.\n",
    "from django.contrib import admin  \n",
    "from django.urls import path  \n",
    "  \n",
    "from django.conf.urls import include  \n",
    "  \n",
    "urlpatterns = [  \n",
    "    path('admin/', admin.site.urls),  \n",
    "    path('', include('search_app.urls')),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_app/urls.py\n",
    "# 이제 Django는 http://127.0.0.1:8000/로 들어오는 모든 접속 요청을 search_app.urls로 전송해 추가 명령을 찾을 것입니다.\n",
    "# search_app 디렉터리에 urls.py 파일을 생성하고 url 패턴을 추가해줍니다.\n",
    "# 참고: https://blog.nerdfactory.ai/2019/04/29/django-elasticsearch-restframework.html\n",
    "from django.urls import path  \n",
    "from search_app import views  \n",
    "  \n",
    "urlpatterns = [  \n",
    "    path('', views.SearchView.as_view()),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시군구코드</th>\n",
       "      <th>지정년도</th>\n",
       "      <th>지정번호</th>\n",
       "      <th>신청일자</th>\n",
       "      <th>지정일자</th>\n",
       "      <th>업소명</th>\n",
       "      <th>소재지도로명</th>\n",
       "      <th>소재지지번</th>\n",
       "      <th>허가(신고)번호</th>\n",
       "      <th>업태명</th>\n",
       "      <th>주된음식</th>\n",
       "      <th>영업장면적(㎡)</th>\n",
       "      <th>행정동명</th>\n",
       "      <th>급수시설구분</th>\n",
       "      <th>소재지전화번호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2021</td>\n",
       "      <td>13</td>\n",
       "      <td>20211025</td>\n",
       "      <td>20211230</td>\n",
       "      <td>늘마중</td>\n",
       "      <td>서울특별시 종로구 인사동10길 11-5, 1층 (관훈동)</td>\n",
       "      <td>서울특별시 종로구 관훈동  30번지 16호</td>\n",
       "      <td>3000000-101-2021-00138</td>\n",
       "      <td>한식</td>\n",
       "      <td>막걸리, 전</td>\n",
       "      <td>59.50</td>\n",
       "      <td>종로1.2.3.4가동</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02  730 2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2021</td>\n",
       "      <td>90</td>\n",
       "      <td>20211126</td>\n",
       "      <td>20211216</td>\n",
       "      <td>끄티집</td>\n",
       "      <td>서울특별시 종로구 삼일대로19길 20, 1~4층 (관철동)</td>\n",
       "      <td>서울특별시 종로구 관철동  14번지 5호</td>\n",
       "      <td>3000000-101-2019-00441</td>\n",
       "      <td>한식</td>\n",
       "      <td>전골, 샤브샤브</td>\n",
       "      <td>445.45</td>\n",
       "      <td>종로1.2.3.4가동</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02725 7772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2021</td>\n",
       "      <td>89</td>\n",
       "      <td>20211025</td>\n",
       "      <td>20211216</td>\n",
       "      <td>말뚜기 감자탕</td>\n",
       "      <td>서울특별시 종로구 종로51길 23-9, 1층 (창신동)</td>\n",
       "      <td>서울특별시 종로구 창신동  581번지 30호  1층</td>\n",
       "      <td>3000000-101-2016-00071</td>\n",
       "      <td>식육(숯불구이)</td>\n",
       "      <td>감자탕</td>\n",
       "      <td>48.92</td>\n",
       "      <td>창신제1동</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2021</td>\n",
       "      <td>88</td>\n",
       "      <td>20210311</td>\n",
       "      <td>20210325</td>\n",
       "      <td>스윗샐러드</td>\n",
       "      <td>서울특별시 종로구 종로1길 50, 더케이트윈타워 지하1층 (중학동)</td>\n",
       "      <td>서울특별시 종로구 중학동  19번지  더케이트윈타워</td>\n",
       "      <td>3000000-101-2018-00205</td>\n",
       "      <td>경양식</td>\n",
       "      <td>샐러드</td>\n",
       "      <td>64.81</td>\n",
       "      <td>종로1.2.3.4가동</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>15</td>\n",
       "      <td>20191030</td>\n",
       "      <td>20191231</td>\n",
       "      <td>대가곱창</td>\n",
       "      <td>서울특별시 종로구 명륜길 53, (명륜3가,(지상1층))</td>\n",
       "      <td>서울특별시 종로구 명륜3가  1번지 1143호  (지상1층)</td>\n",
       "      <td>3000000-101-2009-00015</td>\n",
       "      <td>한식</td>\n",
       "      <td>곱창, 막창</td>\n",
       "      <td>29.37</td>\n",
       "      <td>혜화동</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02  747 3827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>20071112</td>\n",
       "      <td>20071120</td>\n",
       "      <td>진고집 동해 동태탕</td>\n",
       "      <td>서울특별시 종로구 지봉로 26-1, 1층 (숭인동)</td>\n",
       "      <td>서울특별시 종로구 숭인동  313번지 8호</td>\n",
       "      <td>3000000-101-2003-00437</td>\n",
       "      <td>한식</td>\n",
       "      <td>곰탕</td>\n",
       "      <td>158.40</td>\n",
       "      <td>숭인제2동</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02 7780554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>84</td>\n",
       "      <td>20071109</td>\n",
       "      <td>20071120</td>\n",
       "      <td>향가</td>\n",
       "      <td>서울특별시 종로구 계동길 19-6, (재동)</td>\n",
       "      <td>서울특별시 종로구 재동  84번지 1호</td>\n",
       "      <td>3000000-101-2000-11447</td>\n",
       "      <td>한식</td>\n",
       "      <td>시골밥상</td>\n",
       "      <td>200.65</td>\n",
       "      <td>가회동</td>\n",
       "      <td>상수도전용</td>\n",
       "      <td>02 7473368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>20071112</td>\n",
       "      <td>20071120</td>\n",
       "      <td>궁나라냉면.묵밥</td>\n",
       "      <td>서울특별시 종로구 지봉로12길 6, 1층 (숭인동)</td>\n",
       "      <td>서울특별시 종로구 숭인동  56번지 38호</td>\n",
       "      <td>3000000-101-1992-01124</td>\n",
       "      <td>한식</td>\n",
       "      <td>냉면,묵밥</td>\n",
       "      <td>115.50</td>\n",
       "      <td>숭인제1동</td>\n",
       "      <td>상수도전용</td>\n",
       "      <td>02744 4701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>19</td>\n",
       "      <td>20071112</td>\n",
       "      <td>20071120</td>\n",
       "      <td>더레스토랑</td>\n",
       "      <td>서울특별시 종로구 삼청로 54, 지하1,지상1,2층 (소격동)</td>\n",
       "      <td>서울특별시 종로구 소격동  48번지</td>\n",
       "      <td>3000000-101-1999-10390</td>\n",
       "      <td>경양식</td>\n",
       "      <td>스테이크</td>\n",
       "      <td>408.19</td>\n",
       "      <td>삼청동</td>\n",
       "      <td>상수도전용</td>\n",
       "      <td>02 7358441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>41</td>\n",
       "      <td>20071015</td>\n",
       "      <td>20071120</td>\n",
       "      <td>송전</td>\n",
       "      <td>서울특별시 종로구 종로 14, (서린동)</td>\n",
       "      <td>서울특별시 종로구 서린동  136번지</td>\n",
       "      <td>3000000-101-1999-05788</td>\n",
       "      <td>일식</td>\n",
       "      <td>생선회</td>\n",
       "      <td>148.12</td>\n",
       "      <td>종로1.2.3.4가동</td>\n",
       "      <td>상수도전용</td>\n",
       "      <td>02 7398282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      시군구코드  지정년도  지정번호      신청일자      지정일자         업소명  \\\n",
       "0   3000000  2021    13  20211025  20211230         늘마중   \n",
       "1   3000000  2021    90  20211126  20211216         끄티집   \n",
       "2   3000000  2021    89  20211025  20211216     말뚜기 감자탕   \n",
       "3   3000000  2021    88  20210311  20210325       스윗샐러드   \n",
       "4   3000000  2019    15  20191030  20191231        대가곱창   \n",
       "..      ...   ...   ...       ...       ...         ...   \n",
       "85  3000000  2007     9  20071112  20071120  진고집 동해 동태탕   \n",
       "86  3000000  2007    84  20071109  20071120          향가   \n",
       "87  3000000  2007     5  20071112  20071120    궁나라냉면.묵밥   \n",
       "88  3000000  2007    19  20071112  20071120       더레스토랑   \n",
       "89  3000000  2007    41  20071015  20071120          송전   \n",
       "\n",
       "                                   소재지도로명                              소재지지번  \\\n",
       "0         서울특별시 종로구 인사동10길 11-5, 1층 (관훈동)          서울특별시 종로구 관훈동  30번지 16호     \n",
       "1        서울특별시 종로구 삼일대로19길 20, 1~4층 (관철동)           서울특별시 종로구 관철동  14번지 5호     \n",
       "2          서울특별시 종로구 종로51길 23-9, 1층 (창신동)       서울특별시 종로구 창신동  581번지 30호  1층   \n",
       "3   서울특별시 종로구 종로1길 50, 더케이트윈타워 지하1층 (중학동)       서울특별시 종로구 중학동  19번지  더케이트윈타워   \n",
       "4         서울특별시 종로구 명륜길 53, (명륜3가,(지상1층))  서울특별시 종로구 명륜3가  1번지 1143호  (지상1층)   \n",
       "..                                    ...                                ...   \n",
       "85           서울특별시 종로구 지봉로 26-1, 1층 (숭인동)          서울특별시 종로구 숭인동  313번지 8호     \n",
       "86               서울특별시 종로구 계동길 19-6, (재동)            서울특별시 종로구 재동  84번지 1호     \n",
       "87           서울특별시 종로구 지봉로12길 6, 1층 (숭인동)          서울특별시 종로구 숭인동  56번지 38호     \n",
       "88     서울특별시 종로구 삼청로 54, 지하1,지상1,2층 (소격동)              서울특별시 종로구 소격동  48번지     \n",
       "89                 서울특별시 종로구 종로 14, (서린동)             서울특별시 종로구 서린동  136번지     \n",
       "\n",
       "                  허가(신고)번호       업태명      주된음식  영업장면적(㎡)         행정동명 급수시설구분  \\\n",
       "0   3000000-101-2021-00138        한식    막걸리, 전     59.50  종로1.2.3.4가동    NaN   \n",
       "1   3000000-101-2019-00441        한식  전골, 샤브샤브    445.45  종로1.2.3.4가동    NaN   \n",
       "2   3000000-101-2016-00071  식육(숯불구이)       감자탕     48.92        창신제1동    NaN   \n",
       "3   3000000-101-2018-00205       경양식       샐러드     64.81  종로1.2.3.4가동    NaN   \n",
       "4   3000000-101-2009-00015        한식    곱창, 막창     29.37          혜화동    NaN   \n",
       "..                     ...       ...       ...       ...          ...    ...   \n",
       "85  3000000-101-2003-00437        한식        곰탕    158.40        숭인제2동    NaN   \n",
       "86  3000000-101-2000-11447        한식      시골밥상    200.65          가회동  상수도전용   \n",
       "87  3000000-101-1992-01124        한식     냉면,묵밥    115.50        숭인제1동  상수도전용   \n",
       "88  3000000-101-1999-10390       경양식      스테이크    408.19          삼청동  상수도전용   \n",
       "89  3000000-101-1999-05788        일식       생선회    148.12  종로1.2.3.4가동  상수도전용   \n",
       "\n",
       "         소재지전화번호  \n",
       "0   02  730 2985  \n",
       "1     02725 7772  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4   02  747 3827  \n",
       "..           ...  \n",
       "85    02 7780554  \n",
       "86    02 7473368  \n",
       "87    02744 4701  \n",
       "88    02 7358441  \n",
       "89    02 7398282  \n",
       "\n",
       "[90 rows x 15 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype\n",
    "\n",
    "# 사용자로부터 필드 정보 입력받기\n",
    "fields = []\n",
    "print(fields)\n",
    "\n",
    "\n",
    "dd = pd.read_csv(\"C:/Users/jieun/Desktop/project/elastic/data/3_서울시 종로구 모범음식점 지정 현황.csv\")\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jieun\\AppData\\Local\\Temp\\ipykernel_43116\\3336312759.py:2: DeprecationWarning: Importing from the 'elasticsearch.client' module is deprecated. Instead use 'elasticsearch' module for importing the client.\n",
      "  from elasticsearch.client import IndicesClient\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'es' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jieun\\Desktop\\project\\elastic\\code\\token_save.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/token_save.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m index_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m서울시_종로구_모범음식점_지정_현황\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/token_save.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Elasticsearch 인덱스 생성\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/token_save.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m indices_client \u001b[39m=\u001b[39m IndicesClient(es)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/token_save.ipynb#X43sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m field_name \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jieun/Desktop/project/elastic/code/token_save.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m f_type \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mdtypes\n",
      "\u001b[1;31mNameError\u001b[0m: name 'es' is not defined"
     ]
    }
   ],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "from elasticsearch.client import IndicesClient\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "# data_path = \"data/\"\n",
    "# csv_files = os.listdir(data_path)\n",
    "# dataframes = [pd.read_csv(data_path + file) for file in csv_files]\n",
    "# print(csv_files)\n",
    "\n",
    "dd = pd.read_csv(\"C:/Users/jieun/Desktop/project/elastic/data/3_서울시 종로구 모범음식점 지정 현황.csv\")\n",
    "dd = dd.fillna(0)\n",
    "index_name = \"서울시_종로구_모범음식점_지정_현황\"\n",
    "\n",
    "# Elasticsearch 인덱스 생성\n",
    "indices_client = IndicesClient(es)\n",
    "\n",
    "field_name = dd.columns.to_list()\n",
    "f_type = dd.dtypes\n",
    "\n",
    "fields = []\n",
    "for i, field in enumerate(field_name):\n",
    "    field_name = field\n",
    "    field_type = f_type[i]\n",
    "    # print(field_type)\n",
    "    if is_string_dtype(field_type):\n",
    "        fields.append({\n",
    "            \"name\": field_name,\n",
    "            \"type\": \"text\",            # 문자형은 text 타입으로\n",
    "            \"analyzer\": \"my_analyzer\"\n",
    "        })\n",
    "    else:\n",
    "        fields.append({\n",
    "            \"name\": field_name,\n",
    "            \"type\": \"long\"             # 숫자형은 long 타입으로\n",
    "        })\n",
    "\n",
    "# 매핑 설정\n",
    "mappings = {\n",
    "    \"mappings\": {\n",
    "        \"dictionary_datas\": {\n",
    "            \"properties\": {}\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"my_analyzer\": {     ## analyzer 이름 지정\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"nori_tokenizer\",\n",
    "                        \"filter\": [\"lowercase\", \"trim\", \"stop\"],\n",
    "                        \"char_filter\": [\"html_strip\"],\n",
    "                        \"filter\": [\"my_filter\"]\n",
    "                    }\n",
    "                },\n",
    "                \"filter\":{\n",
    "                    \"my_filter\":{\n",
    "                        \"type\":\"pattern_replace\",\n",
    "                        \"pattern\": \"[^a-zA-Z0-9가-힣\\\\s]\",\n",
    "                        \"replacement\": \"\"\n",
    "                    }  \n",
    "                },\n",
    "                \"tokenizer\": {           ## tokenizer 이름 지정\n",
    "                    \"my_tokenizer\": {\n",
    "                        \"type\": \"nori_tokenizer\",\n",
    "                        \"decompound_mode\": \"mixed\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 사용자가 입력한 필드 정보를 기반으로 매핑 설정 추가\n",
    "for field_info in fields:\n",
    "    field_name = field_info[\"name\"]\n",
    "    field_type = field_info[\"type\"]\n",
    "\n",
    "    if field_type == 'text':\n",
    "        analyzer_name = field_info[\"analyzer\"]\n",
    "        mappings[\"mappings\"][\"dictionary_datas\"][\"properties\"][field_name] = {\n",
    "        \"type\": field_type,\n",
    "        \"analyzer\": \"my_analyzer\"\n",
    "    }\n",
    "    else:\n",
    "        mappings[\"mappings\"][\"dictionary_datas\"][\"properties\"][field_name] = {\n",
    "        \"type\": field_type\n",
    "    }\n",
    "\n",
    "# 인덱스 생성 및 매핑 설정 적용\n",
    "indices_client.create(index=index_name, body={\"settings\": mappings})\n",
    "\n",
    "# CSV 데이터를 Elasticsearch에 업로드\n",
    "data = dataframe.to_dict(orient='records')\n",
    "actions = [{\"_index\": index_name, \"_source\": item} for item in data]\n",
    "print(actions)\n",
    "bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mappings': {'dictionary_datas': {'properties': {'시군구코드': {'type': 'long'},\n",
       "    '지정년도': {'type': 'long'},\n",
       "    '지정번호': {'type': 'long'},\n",
       "    '신청일자': {'type': 'long'},\n",
       "    '지정일자': {'type': 'long'},\n",
       "    '업소명': {'type': 'text'},\n",
       "    '소재지도로명': {'type': 'text'},\n",
       "    '소재지지번': {'type': 'text'},\n",
       "    '허가(신고)번호': {'type': 'text'},\n",
       "    '업태명': {'type': 'text'},\n",
       "    '주된음식': {'type': 'text'},\n",
       "    '영업장면적(㎡)': {'type': 'long'},\n",
       "    '행정동명': {'type': 'text'},\n",
       "    '급수시설구분': {'type': 'text'},\n",
       "    '소재지전화번호': {'type': 'text'}}}},\n",
       " 'settings': {'index': {'analysis': {'analyzer': {'my_analyzer': {'type': 'custom',\n",
       "      'tokenizer': 'nori_tokenizer'}}}}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매핑 설정\n",
    "mappings = {\n",
    "    \"mappings\": {\n",
    "        \"dictionary_datas\": {\n",
    "            \"properties\": {}\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "            \"index\": {\n",
    "                \"analysis\": {\n",
    "                    \"analyzer\": {\n",
    "                        \"my_analyzer\": {\n",
    "                            \"type\": \"custom\",\n",
    "                            \"tokenizer\": \"nori_tokenizer\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "# 사용자가 입력한 필드 정보를 기반으로 매핑 설정 추가\n",
    "for field_info in fields:\n",
    "    field_name = field_info[\"name\"]\n",
    "    field_type = field_info[\"type\"]\n",
    "\n",
    "    if is_string_dtype(field_type):\n",
    "        analyzer_name = field_info[\"analyzer\"]\n",
    "        mappings[\"mappings\"][\"dictionary_datas\"][\"properties\"][field_name] = {\n",
    "        \"type\": field_type,\n",
    "        \"analyzer\": analyzer_name\n",
    "    }\n",
    "    else:\n",
    "        mappings[\"mappings\"][\"dictionary_datas\"][\"properties\"][field_name] = {\n",
    "        \"type\": field_type\n",
    "    }\n",
    "\n",
    "mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# model_id = \"EleutherAI/polyglot-ko-12.8b\"\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    target_modules=[\"query_key_value\"], \n",
    "    lora_dropout=0.05, \n",
    "    bias=\"none\", \n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykg2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
